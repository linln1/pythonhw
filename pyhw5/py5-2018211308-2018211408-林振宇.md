# Python程序设计#5作业

截止时间：2020年11月23日23:59:59

## 作业题目

在作业#4的基础上实现remoteProxy对每个用户进行单独流控

SQLite3数据库的每个用户的账号信息中增加带宽信息（用户名、密码、带宽）

带宽的单位为BPS（Bytes / Second，字节每秒），该带宽为某个用户的所有连接的转发数据总和带宽。

此次作业需要在【代码说明】中陈述流控的技术方案和实现机制。

## 作业内容

程序源代码嵌入下方的code block中。

```python

import asyncio
import ipaddress
import logging
import signal
import struct
import sqlite3
import aiosqlite
import argparse
from time import time
from threading import RLock, Timer
import better_exceptions

from enum import Enum
ReadMode = Enum('ReadMod', ('EXACT', 'LINE', 'MAX', 'UNTIL'))

remoteProxyHost = '127.0.0.1'
remoteProxyPort = 8889
remotesocksPort = 8890
uBucketdict = dict()
sBucketdict = dict()
DataBaseLock = RLock()

class MyError(Exception):
    pass

async def aioClose(w, *, logHint=None):
    if not w:
        await asyncio.sleep(0.001)
        return
    host, port, *_ = w.get_extra_info('peername')
    log.info(f'{logHint} close... peer {host} {port}')
    try:
        w.close()
        await w.wait_closed()
    except Exception as exc:
        pass

async def aioRead( r, mode, *, logHint=None, exactData=None, exactLen=None, maxLen=-1, untilSep=b'\r\n', user = None, bucket = None):
    data = None
    uBucket = None
    if user:
        uBucket = uBucketdict[user]  # 取出这个用户拥有的桶，所有的数据经过桶过滤一次之后再发出去就可以，每次发送出去的数据是从桶里面取出来的
    if bucket:
        uBucket = bucket
    try:
        if ReadMode.EXACT == mode:
            exactLen = len(exactData) if exactData else exactLen
            data = await r.readexactly(exactLen)
            if exactData and data != exactData:
                raise MyError(f'recvERR={data} {logHint}')
        elif ReadMode.LINE == mode:
            data = await r.readline()
        elif ReadMode.MAX == mode:
            data = await r.read(maxLen)
        elif ReadMode.UNTIL == mode:
            data = await r.readuntil(untilSep)
        else:
            log.error(f'INVALID mode={mode}')
            exit(1)
    except ConnectionResetError as exc:
        raise MyError(f'recvEXC={exc} {logHint}')
    except ConnectionAbortedError as exc:
        raise MyError(f'recvEXC={exc} {logHint}')
    if not data:
        raise MyError(f'recvEOF {logHint}')
    if uBucket:
        uBucket.input(data) #将数据放入桶内
    return data

async def aioWrite(w, data, *, logHint=''):
    try:
        w.write(data)
        await w.drain()
    except ConnectionAbortedError as exc:
        raise MyError(f'sendEXC={exc} {logHint}')

async def recieve_data_from_local(cl_reader, logHint=None, user=None):
    try:
        while True:
            data = await aioRead(cl_reader, ReadMode.MAX, maxLen=65535, logHint='', bucket=uBucketdict[user])#从用户接收数据请求，并且放入uBucket[user]桶内
            #print(data)
    except MyError as exc:
        log.info(f'{logHint} {exc}')

# 这个函数和上面的不同，只要有数据，就会不停的发
async def send_data_to_server(rm_writer, logHint= None, user=None):
    try:
        uBucket = uBucketdict[user]
        conn = sqlite3.connect('cache.db')
        c = conn.cursor()
        print('open cache.db')
        while True:
            start = time()
            if uBucket.status:
                dps = uBucket.write(args.lim)#从桶里面获得的数据，如果<args.lim,就代表目前桶内流出速度大于流入速度，还有多余的带宽
                DataBaseLock.acquire()#对于更改数据库操作需要加锁
                c.execute("UPDATE USER SET BANDWITH=? WHERE USERNAME=?", (len(dps), user,))#这里要更新user的带宽数据
                DataBaseLock.release()#改完释放
                await aioWrite(rm_writer, dps, logHint='')#以data_per_second的速率向rm_writer写数据
            timenow = time()#记录现在的时刻
            if(timenow - start < 1):#如果经过的时间<1s,那就剩下的时间休眠
                await asyncio.sleep(1 - (timenow - start))#休眠
    except MyError as exc:
        log.info(f'{logHint} {exc}')

async def transfer_client_remote(cl_reader, rm_writer, logHint=None, user=None):
    try:
        while True:
            data = await aioRead(cl_reader, ReadMode.MAX, maxLen=65535, logHint='')
            await aioWrite(rm_writer, data, logHint='')
    except MyError as exc:
        log.info(f'{logHint} {exc}')

async def transfer_remote_client(rm_reader, cl_writer, logHint=None, user=None):
    try:
        while True:
            data = await aioRead(rm_reader, ReadMode.MAX, maxLen=65535, logHint='recv data from server')
            await aioWrite(cl_writer, data, logHint='')
    except MyError as exc:
        log.info(f'{logHint} {exc}')

async def socks5ReadDstHost(r, atyp, *, logHint):
    。。。

def socks5EncodeBindHost(bindHost):
    。。。

async def remoteProxyRun(reader, writer, logHint=None):
    rm_reader, rm_writer = None, None
    submit = await aioRead(reader, ReadMode.LINE)
    if submit.decode().split(" ")[0] == "sumbit:":
        params = submit.decode().split(" ")
        username, password = params[1], params[2]
        current_throughput = 0
        async with aiosqlite.connect('cache.db') as db:
            async with db.execute('SELECT * FROM USER WHERE USERNAME=? and PASSWORD=?', (username, password, ) ) as cur:
                async for row in cur:
                    current_throughput = row[2]
                # print("now into database")
                if current_throughput >= int(args.lim):  #超速那么就拒绝服务
                    print("server is too busy, please try to connect again after a while")
                    return
                version = await aioRead(reader, ReadMode.EXACT, exactLen=1, logHint=f'1stByte')
                if b'\x05' == version:
                    proxyType = 'SOCKS5'
                    numMethods = await aioRead(reader, ReadMode.EXACT, exactLen=1, logHint='nMethod')
                    await aioRead(reader, ReadMode.EXACT, exactLen=numMethods[0], logHint='methods')
                    await aioWrite(writer, b'\x05\x00', logHint='method.noAuth')
                    await aioRead(reader, ReadMode.EXACT, exactData=b'\x05\x01\x00', logHint='verCmdRsv')
                    atyp = await aioRead(reader, ReadMode.EXACT, exactLen=1, logHint='atyp')
                    dstHost = await socks5ReadDstHost(reader, atyp, logHint='dstHost')
                    dstPort = await aioRead(reader, ReadMode.EXACT, exactLen=2, logHint='dstPort')
                    dstPort = int.from_bytes(dstPort, 'big')
                    # 连接远程代理服务器

                    rm_reader, rm_writer = await asyncio.open_connection(dstHost, dstPort)
                    bindHost, bindPort, *_ = rm_writer.get_extra_info('sockname')

                    atyp, hostData = socks5EncodeBindHost(bindHost)
                    data = struct.pack(f'!ssss{len(hostData)}sH', b'\x05', b'\x00', b'\x00', atyp, hostData, int(bindPort))
                    await aioWrite(writer, data, logHint='reply')

                else:
                    proxyType = 'HTTP TUNNEL'
                    line = await aioRead(reader, ReadMode.LINE, logHint='Connection Request Header')
                    line = version + line
                    req_headers = await aioRead(reader, ReadMode.UNTIL, untilSep=b'\r\n\r\n',
                                                logHint='Request Header')
                    line = line.decode()
                    method, uri, proto, *_ = line.split()

                    if 'connect' == method.lower():
                        proxyType = 'HTTPS'
                        logHint = f'{logHint} {proxyType}'
                        i = uri.find(':')
                        if i:
                            dstHost, dstPort = uri[:i], uri[i + 1:]
                        else:
                            dstHost, dstPort = uri, 8889
                    else:
                        raise MyError(f'RECV INVALID={line.strip()} EXPECT=CONNECT')
                    # 连接远程代理并且发送数据
                    logHint = f'{logHint} {dstHost} {dstPort}'
                    log.info(f'{logHint} connStart...')
                    try:
                        rm_reader, rm_writer = await asyncio.open_connection(dstHost, int(dstPort))
                        reply = f'HTTP/1.1 200 OK\r\n\r\n'
                        await aioWrite(writer, reply.encode())
                    except Exception as Err:
                        MyError(Err)
                        reply = "HTTP/1.1" + str(Err) + " Fail\r\n\r\n"
                        await aioWrite(writer, reply.encode())

                if rm_writer:
                    print('call transfer data proc')
                    await asyncio.wait({
                        asyncio.create_task(recieve_data_from_local(reader, user=username)),#接受来自用户的数据，并放入桶内
                        asyncio.create_task(send_data_to_server(rm_writer,user=username)),#向服务器限速发送数据

                        asyncio.create_task(transfer_remote_client(rm_reader, writer))#接受来自服务器的数据返回给用户
                    })


async def remoteTask(port): #启动远程代理服务器
    rm_srv = await asyncio.start_server(remoteProxyRun, host=remoteProxyHost, port=port)
    addrList = list([s.getsockname() for s in rm_srv.sockets])
    log.info(f'LISTEN Client Proxy {addrList}')
    async with rm_srv:
        await rm_srv.serve_forever()

class leakyBucket(object):
    def __init__(self, username,  capacity, leak_rate):
        '''
        :param capacity: the total data in the bucket
        :param leak_rate: the rate data per seconds that the bucket leaks
        :param :
        '''
        self.owner = username                         #桶的拥有者
        self._capacity = capacity                     #容量
        self._used_tokens = 0                         #留作令牌桶
        self._leak_rate = leak_rate                   #漏桶速度
        self._last_time = 0                           #上一次收到数据的时刻
        self._lock = RLock()                           #桶锁
        self._data = ""                               #数据
        self.status = False                            #是否不为空

    #要更新现在桶的数据量
    def input(self, data):
        data = data.decode()
        newdatalen = len(data)
        self._lock.acquire()            #加锁
        if len(self._data) + newdatalen < self._capacity:       #如果新来的数据+现有的数据<桶的最大容量
            self._data = self._data + data                      #把新数据放入桶内
        else:
            self._data = self._data + data[:self._capacity - len(self._data)]           #把溢出的部分丢去
            print("data overflow out of the bucket {}" % data[self._capacity - len(self._data):])
        self._last_time = time()            #记录时间
        if len(data):#桶内有数据
            self.status = True
        self._lock.release()            #释放锁

    def write(self, lens):
        lens = int(lens)            #lens转换为int
        self._lock.acquire()        #加锁
        output = self._data[:lens] if (len(self._data) >= lens) else self._data     #如果桶内数据富余，就输出长度为len的数据
        self._data = self._data[lens:] if (len(self._data) >= lens) else ""         #否则，剩多少，输出多少
        if len(self._data) == 0:                                                    #桶内无数据时
            self.status = False                                                     #状态改为False
        self._lock.release()
        return output.encode()


def init_database():
    conn = sqlite3.connect('cache.db')
    c = conn.cursor()
    c.execute('''DROP TABLE IF EXISTS USER ;''')
    c.execute('''CREATE TABLE USER
               (USERNAME           TEXT    NOT NULL,
               PASSWORD           TEXT      ,
               BANDWIDTH        DOUBLE      );''')
    print("Table created successfully")

    #给每个用户增加带宽属性
    c.execute('''INSERT INTO USER(USERNAME, PASSWORD, BANDWIDTH) VALUES ('u1', '11', 0);''')
    c.execute('''INSERT INTO USER(USERNAME, PASSWORD, BANDWIDTH) VALUES ('u2', '22', 0);''')
    c.execute('''INSERT INTO USER(USERNAME, PASSWORD, BANDWIDTH) VALUES ('u3', '33', 0);''')

    # 为每个用户创建俩个桶，一个向服务器发送请求，控制发送方的流量，另一个接受来自服务器的响应，控制服务器下行流量，用来缓存数据
    for user in ['u1', 'u2', 'u3']:
        uBucketdict[user] = leakyBucket(user, args.cap, args.lim)
        sBucketdict[user] = leakyBucket(user, args.cap, args.lim)

    c.execute("SELECT * FROM USER")
    for row in c:
        print("NAME = ", row[0])
        print("PASSWORD = ", row[1])
        print("BANDWIDTH = ", row[2])

async def main():
    init_database()
    t1 = asyncio.create_task(remoteTask(remoteProxyPort))  # 创建任务
    t2 = asyncio.create_task(remoteTask(remotesocksPort))
    await asyncio.gather(t1, t2)
    while True:
        await asyncio.sleep(1)

if __name__ == '__main__':
    signal.signal(signal.SIGINT, signal.SIG_DFL)

    _logFmt = logging.Formatter('%(asctime)s %(levelname).1s %(lineno)-3d %(funcName)-20s %(message)s', datefmt='%H:%M:%S')
    _consoleHandler = logging.StreamHandler()
    _consoleHandler.setLevel(logging.DEBUG)
    _consoleHandler.setFormatter(_logFmt)

    log = logging.getLogger(__file__)
    log.addHandler(_consoleHandler)
    log.setLevel(logging.DEBUG)

    _parser = argparse.ArgumentParser(description='add traffic control')
    _parser.add_argument('--limit', dest='lim', metavar='lim', default='15000', help='the limit of the web ')# default = 1.5KB/s 就是桶每秒流出的数据量
    _parser.add_argument('--capacity', dest='cap', metavar='cap', default = '10000000', help='the capacity of the bucket')# default = 1MB 就是桶的容量

    args = _parser.parse_args()
    asyncio.run(main())
```

## 代码说明

首先实现了令牌桶类
令牌桶类有两个函数，
一个input函数接受来自外部的数据流，其中，如果当前到来的数据会溢出桶，就让它溢出，在加入令牌桶的时候，需要请求锁，桶内数据修改完之后释放锁。
另一个函数output将数据以恒定速率发送到外部，如果数据不足BPS,就发送剩下的所有数据，在令牌桶向外泄露数据的时候，也需要锁，数据流出后，就不会再存在于桶内，然后释放锁。

其中对于远程服务器认证部分和转发数据部分做了修改
对于初始化数据库，增加了BANDWITH属性，用来记录每个用户的流速。
当有用户通过命令试图连接远程服务器的时候，首先进行用户名密码登录验证，然后检查当前该用户的带宽，
如果超过了限制，就拒绝该用户的连接。返回服务器繁忙的信息。

对于每个用户，有两个令牌桶实例，一个接受来自本地代理发送的数据，然后以限定的流速发送给远方服务器，
另一个接受来自服务器的响应，以固定的速率返回给用户。
这个利用字典来实现，一个username 对应 两个实例uBucket和sBucket。
remote_proxy所有收到的数据都要经过令牌桶，利用aioRead来实现，
其中向aioRead函数传递两个参数 user bucket
当传递了user的时候，可以通过字典查找user对应的uBucket，然后将数据读入uBucket
当传递了bucket的时候，就有可能是uBucket或者是sBucket，也就是有可能收到的是来自服务器的响应信息，也有可能是来自local_proxy的请求信息

然后三个函数，分别实现接收local_proxy请求，向远程server发送请求，接受server响应并且向local_proxy返回响应，这里面从用户来的信息和发向服务器的信息
要经过桶，在数据库登录认证成功后，被当作并发任务启动

其中向外发送数据需要计算BPS，Bytes Per Second， 也就是控制流量小于传进来的参数lim，
就是在发送之前开始计时，等待aioWrite(w, len=args.lim); 然后sleep(1-发送数据经过的时间)，这样可以保证
发送数据速率不会超过限制，这里还有一个问题，就是如果发送args.lim的时间已经超出1s，那么sleep时候会出错，
所以我加了一个判，避免出sleep负值这样的错误，同时向数据库中写入BANDWTIH=args.lim
如果当前桶内数据小于args.lim,记当前数据长度是len, 那么当前发送速率就是len,也就可以允许同用户多点登录发送请求


实际上对于同一个用户多个登录点，只要用户名和密码是一样的，都使用的是同一个桶，只要这个桶的总的速率控制在args.lim, 那么无论多少同名同时登录，总的流量依然是控制在lim之下的


